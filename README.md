# Week 1: Basic Setup ‚Äì Data Engineering with Docker and PostgreSQL

This project demonstrates how to use **Docker** to build a reproducible environment for loading NYC Taxi CSV data into a **PostgreSQL** database using **Python** and **SQLAlchemy**.

## üìÅ Folder Structure

This folder contains the following key files:

- `load_data_2_postgres.py`:  
  Python script to load CSV data into a PostgreSQL database using SQLAlchemy and pandas.

- `Dockerfile`:  
  Dockerfile to create an image that installs Python, required packages, and runs the `load_data_2_postgres.py` script.

- `docker-compose.yaml`:  
  (Optional) File to spin up both the PostgreSQL container and the data loading container together.

- `parquet_to_csv.ipynb`:  
  Jupyter Notebook to convert Parquet data to CSV format (for pre-processing).  to activate use command 'docker-compose up -d'


- `postgres_data/`:  
  Volume for PostgreSQL data persistence.


## üöÄ How to Build and Run the Container

### Step 1: Ch·∫°y PostgreSQL 13 B·∫±ng Docker

```bash
Ch·∫°y l·ªánh sau trong th∆∞ m·ª•c week_1_basic_n_setup: powershell
        'docker-compose up -d'
ÔøΩÔøΩ Gi·∫£i th√≠ch l·ªánh:
o docker-compose up -d: Ch·∫°y Docker Compose ·ªü ch·∫ø ƒë·ªô n·ªÅn (detached mode).
o T·ª± ƒë·ªông t·∫£i v·ªÅ PostgreSQL 13 v√† pgAdmin n·∫øu ch∆∞a c√≥.
o T·∫°o v√† kh·ªüi ƒë·ªông c√°c container pgdatabase (PostgreSQL) v√† pgadmin.



